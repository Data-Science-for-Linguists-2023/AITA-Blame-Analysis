{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7412fdc",
   "metadata": {},
   "source": [
    "# Initial Data Collection\n",
    "\n",
    "This project utilizes both [PRAW](https://praw.readthedocs.io/en/latest/index.html) and [PMAW](https://github.com/mattpodolak/pmaw) to scrape submission data from [r/AmITheAsshole](https://www.reddit.com/r/AmItheAsshole/). PRAW is a wrapper for the Reddit API. However, through Reddit's built-in API, you cannot query data past a certain time limit and can only query 1000 posts at a time. However, the third-party Pushshift API allows you to query older and larger quantities of data. PMAW is a wrapper for the Pushshift API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ed9fec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "from pmaw import PushshiftAPI\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1df59b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reddit = praw.Reddit(client_id = \"IvW7ZTnW2wwAHC5fSLeU2w\",\n",
    "#                     client_secret = \"PtgEzUzpF1jGLt17ukSvoo0OptnCwA\",\n",
    "#                     user_agent = \"AITA Scrapping /u/amo104\")\n",
    "\n",
    "api = PushshiftAPI(file_checkpoint=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2cd0ed",
   "metadata": {},
   "source": [
    "From each post, I will be saving the poster's username, the post title, the text, the number of upvotes, the ratio of upvotes to downvotes (Reddit API has removed access to the exact number of downvotes), and any post flairs. On this subreddit, flairs are used to track the final verdicts on \"Asshole\", \"Not the A-hole\", \"No a-holes here\", and \"Everyone Sucks.\" Further information on how this subreddit categorizes posts can be found in their [FAQ](https://www.reddit.com/r/AmItheAsshole/wiki/faq/#wiki_acronyms)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ad7401",
   "metadata": {},
   "source": [
    "Because scraping posts will take a considerable amount of time and I intend to end in a corpus with over 10,000 posts, I will be using this notebook to test out the organization and cleaning process before running this on a larger number of posts. For now, the notebook processing the entire corpus and its resulting .csv is tracked by .gitignore until I'm sure there's nothing present that needs to be omitted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ea0ff8",
   "metadata": {},
   "source": [
    "Pushshift is also undergoing a migration process and does not have any data from before November 2022 ready. Because of this, I'll only be using data from this year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e5778ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "before = int(dt.datetime(2023, 1, 7, 0, 0).timestamp())\n",
    "after = int(dt.datetime(2023, 1, 1, 0, 0).timestamp())\n",
    "\n",
    "submissions = api.search_submissions(subreddit=\"AmItheAsshole\", until=before, since=after, limit=1000, mem_safe=True)\n",
    "print(len(submissions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "646febe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>selftext</th>\n",
       "      <th>author_fullname</th>\n",
       "      <th>gilded</th>\n",
       "      <th>title</th>\n",
       "      <th>link_flair_richtext</th>\n",
       "      <th>subreddit_name_prefixed</th>\n",
       "      <th>hidden</th>\n",
       "      <th>pwls</th>\n",
       "      <th>link_flair_css_class</th>\n",
       "      <th>...</th>\n",
       "      <th>num_crossposts</th>\n",
       "      <th>media</th>\n",
       "      <th>is_video</th>\n",
       "      <th>retrieved_utc</th>\n",
       "      <th>updated_utc</th>\n",
       "      <th>utc_datetime_str</th>\n",
       "      <th>link_flair_template_id</th>\n",
       "      <th>author_cakeday</th>\n",
       "      <th>post_hint</th>\n",
       "      <th>preview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AmItheAsshole</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>t2_a8